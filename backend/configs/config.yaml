curate:
  batch_size: 8
  threshold: 7.0
  temperature: 0.1 
  inference_batch: 8
generation:
  chunk_size: 4000
  num_pairs: 25
  temperature: 0.7
vllm:
  api_base: http://localhost:8000/v1
  model: meta-llama/Llama-3.3-70B-Instruct
prompts:
  qa_rating: |
    You are a quality evaluator for question-answer pairs. Your task is to rate the quality of each given Q&A pair on a scale of 1-10.

    Rate based on these criteria:
    1. Relevance - Does the Q&A directly relate to the subject matter?
    2. Accuracy - Is the answer factually correct given the question?
    3. Completeness - Does the answer thoroughly address all aspects of the question?
    4. Clarity - Is the question clear and unambiguous? Is the answer well-articulated?
    5. Educational value - Does the Q&A provide valuable information?

    For each pair, provide:
    1. A numerical rating from 1-10, where 10 is excellent quality
    2. A brief justification for your rating

    Here are the Q&A pairs to evaluate:
    {pairs}

    Format your response as a valid JSON array with each object containing the original question, answer, your rating, and justification:
    [
      {
        "question": "Original question text",
        "answer": "Original answer text",
        "rating": 8,
        "justification": "Brief explanation of rating"
      },
      ...
    ]
